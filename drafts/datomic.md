Я удалил Datomic из проекта.

В апреле 2023 Datomic стал бесплатным и я загорелся идеей добавить его в проект,
т.к. была потребность в транзакционной БД и кэшировании данных в приложении.
За эти 2 года он так и не прижился у нас. Расскажу в этой заметке немного про его внутренности
и недостатки.

Чтобы понимать мою экспертность в вопросе
1. я контрибутил в DataScript
2. я написал [Hazel](https://github.com/darkleaf/hazel) - читателя индексов DataScript на js.

Т.е. я довольно глубоко понимаю дизайн и внутреннее устройство Datomic OnPrem.

Изначально я рассматривал датомик для
1. генерации коротких (int64) id для сущностей
2. хранению настроек приложений
3. простой проверки, что данные изменились
4. хранению больших документов - описаний дашбордов
5. т.к. данные бы менялись редко, то локальный кэш выглядел заманчиво

# Утечка T-counter

Датомик хранит данные тройками `[entity attribute value]`.
`entity` тут как раз номер - идентификатор сущности.

Узнать подробности о структуре битов можно из статьи
[Datomic Entity Id and Datom Internals](https://favila.github.io/2024-05-16/datomic-entity-id-structure/).

Для нас тут важно, что независимо от партиции, что на t-counter выделяется 42 бита.
Этот счетчик монотонно растет при создании новой сущности.

Давайте прикинем на сколько этого хватит

`2^42 / 5000TPS / 60 / 60  / 24 / 365 = 27 years`.
Т.е. мы можем коммитить 27 лет 5000 транзакций в секунду, где создается только одна сущность - сама транзакция.
Т.к. датомик создает сущность, описывающую транзакцию.
В реальности же на одну транзакцию будет создание пары сущностей.

Вроде бы числа получаются большие, но недостаточно.

Например, если мы выполняли транзакцию, которая не изменила данные, то счетчик все равно увеличится,
т.к. датомик записывает время выполнения траназкци, а значет создает сучщность транзакции.
Это важно понимать при выполнении "upsert" транзакциях.

# Декантирование

В сообществе появился термин `Decanting` - переливание данных из одного инстанса Datomic в новый
путем чтения лога транзакций и фильтрацией ненужных записей.

Это нужно, когда история занимает слишком много данных, или нужно удалить много данных.

Возвращаясь к утечке t-counter - декантирование может помочь, но только если entid оставались приватными,
а в качестве публичных ключей использовался UUID или что-то похожее.
Т.е. при декантировании мы могли бы изменять entid сущностей.

Одной из целей внедрения Datomic в мой проект, были как раз Int64 идентификаторы.
В документации даже писали, что не стоит их делать публичными, но теперь я осознаю эту рекомендацию.

# API для удаления данных

Для некоторых проектов важно иметь возможность надежно удалить данные.
В datomic есть api для этого. Но там есть много нюансов, в том числе связанных с производительностью.
Например удаление может остановить транзакции.

Вместо удаления обычно используют декантирование. Класс!

# Multitenancy

Может показаться, раз у нас БД как значение и мы можем применять `d/filter`, то пробем с multitenancy нет.
Но это не так. В документации или сообщесте нет никаких наработок в этой области.

Нельзя просто взять и изолировать данные разных клиетов.
Нужно довольно глубоко погружаться во внутренности датомика, чтобы сделать безопасное и удобное решение.

От себя замечу, что если клиентов мало (524_288), то можно разделять их по разным [implicit partitions](https://blog.datomic.com/2023/04/implicit-partitions.html).

# Индексы

Есть EAVT, AEVT, AVET, VAET. Для поиска по значению атрибута будет использоваться AVET.
И это одна из причин, почему все говорят, что датомик медленный.
Он не медленный, просто нужна экспертиза, чтобы учитывать раскладку данных в индексе.

Например, у нас есть Платформа приложения (java, ruby, ....) и Имя приложения.
И зная их мы хотим найти Идентификатор приложения (пусть будет UUID).
Кроме того, они содержатся в аккаунтах, но оставим их за скобками.

Нам нужно выбрать какой атрибут поставить первым в `:where`: Платформу или Имя.
Нужно выбрать Имя, как самый высоко кардинальный атрибут.
Но что, если и платформ тоже много, и одно Имя встречается во многих Платформах?
Тогда мы выберем много лишних данных, что снизит скорость запроса.

Решение этого Composite tuples - мы сможем положить в один атрибут и платформу и имя,
тем самым увеличив кардинальность множества значений.

У этого есть проблемы.
Нужно учитывать это при создании схемы. А если мы не учли, то нужен процесс миграции, чтобы
добавить этот атрибут существующим сущностям.
А это куда сложнее, чем `CREATE INDEX CONCURRENTLY`.

# Тразакции

Для меня, как пользователя есть несколько

1. не видно изменения
2. нельзя вернуть значение
3. транзакции, которые ничего не пишут - расходуют счетчик

# Деплой

Проблемы из-за количества тредов хэлсчека.

Официальный докер

# Доступ к данным без репл

нет консоли, чтобы потрогать данные

# Масштабирование

не нужно сейчас горизонтальное масштабирование

# всякое

простгрес тоже не отадет данные после удаления, но там есть инструменты
