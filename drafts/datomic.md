Я удалил Datomic из проекта.

В апреле 2023 Datomic стал бесплатным и я загорелся идеей добавить его в проект,
т.к. была потребность в транзакционной БД и кэшировании данных в приложении.
За эти 2 года он так и не прижился у нас. Расскажу в этой заметке немного про его внутренности
и недостатки.

Чтобы понимать мою экспертность в вопросе
1. я контрибутил в DataScript
2. я написал [Hazel](https://github.com/darkleaf/hazel) - читателя индексов DataScript на js.

Т.е. я довольно глубоко понимаю дизайн и внутреннее устройство Datomic OnPrem.

Изначально я рассматривал датомик для
1. генерации коротких (int64) id для сущностей
2. хранению настроек приложений
3. простой проверки, что данные изменились
4. хранению больших документов - описаний дашбордов
5. т.к. данные бы менялись редко, то локальный кэш выглядел заманчиво

# Утечка T-counter

Датомик хранит данные тройками `[entity attribute value]`.
`entity` тут как раз номер - идентификатор сущности.

Узнать подробности о структуре битов можно из статьи
[Datomic Entity Id and Datom Internals](https://favila.github.io/2024-05-16/datomic-entity-id-structure/).

Для нас тут важно, что независимо от партиции, что на t-counter выделяется 42 бита.
Этот счетчик монотонно растет при создании новой сущности.

Давайте прикинем на сколько этого хватит

`2^42 / 5000TPS / 60 / 60  / 24 / 365 = 27 years`.
Т.е. мы можем коммитить 27 лет 5000 транзакций в секунду, где создается только одна сущность - сама транзакция.
Т.к. датомик создает сущность, описывающую транзакцию.
В реальности же на одну транзакцию будет создание пары сущностей.

Вроде бы числа получаются большие, но недостаточно.

Например, если мы выполняли транзакцию, которая не изменила данные, то счетчик все равно увеличится,
т.к. датомик записывает время выполнения траназкци, а значет создает сучщность транзакции.
Это важно понимать при выполнении "upsert" транзакциях.

# Декантирование

В сообществе появился термин `Decanting` - переливание данных из одного инстанса Datomic в новый
путем чтения лога транзакций и фильтрацией ненужных записей.

Это нужно, когда история занимает слишком много данных, или нужно удалить много данных.

Возвращаясь к утечке `t-counter` - декантирование может помочь, но только если entid оставались приватными,
а в качестве публичных ключей использовался UUID или что-то похожее.
Т.е. при декантировании мы могли бы изменять entid сущностей.

Одной из целей внедрения Datomic в мой проект, были как раз Int64 идентификаторы.
В документации даже писали, что не стоит их делать публичными, но теперь я осознаю эту рекомендацию.

# API для удаления данных

Для некоторых проектов важно иметь возможность надежно удалить данные.
В datomic есть api для этого. Но там есть много нюансов, в том числе связанных с производительностью.
Например удаление может остановить транзакции.

Вместо удаления обычно используют декантирование. Класс!

# Multitenancy

Может показаться, раз у нас БД как значение и мы можем применять `d/filter`, то пробем с multitenancy нет.
Но это не так. В документации или сообщесте нет никаких наработок в этой области.

Нельзя просто взять и изолировать данные разных клиетов.
Нужно довольно глубоко погружаться во внутренности датомика, чтобы сделать безопасное и удобное решение.

От себя замечу, что если клиентов мало (524_288), то можно разделять их по разным [implicit partitions](https://blog.datomic.com/2023/04/implicit-partitions.html).

# Индексы

Есть EAVT, AEVT, AVET, VAET. Для поиска по значению атрибута будет использоваться AVET.
И это одна из причин, почему все говорят, что датомик медленный.
Он не медленный, просто нужна экспертиза, чтобы учитывать раскладку данных в индексе.

Например, у нас есть Платформа приложения (java, ruby, ....) и Имя приложения.
И зная их, мы хотим найти Идентификатор приложения (пусть будет UUID).
Кроме того, они содержатся в аккаунтах, но оставим это за скобками.

Нам нужно выбрать, какой атрибут поставить первым в `:where`: Платформу или Имя.
Нужно выбрать Имя, как самый высоко кардинальный (селективный) атрибут.
Но что, если и платформ тоже много, и одно Имя встречается во многих Платформах?
Тогда мы выберем много лишних данных, что снизит скорость запроса.

Решение этой проблемы - Composite tuples.
С их помощью мы сможем положить в один атрибут и Платформу и Имя,
тем самым увеличив кардинальность множества значений.

У этого есть проблемы.
Нужно учитывать это при создании схемы. А если мы не учли, то нужен процесс миграции, чтобы
добавить этот атрибут существующим сущностям.
А это куда сложнее, чем `CREATE INDEX CONCURRENTLY`.

# AEVT

Я так и не придумал зачем нужен этот индекс. Если кто-то знает - расскажите.

Проблема в том, что из-за него данные хранятся 2 раза: в EAVT и в AEVT.

# Тразакции не видят свои изменения

Transaction function это функция, которая выполняется в транзакеторе.
Она принимает базу, параметры и возвращает tx-data.

Проблема в том, что другой вызов функции в той же транзакции не увидит изменений первой фукнции.
Например это делает сложным инкремент атрибута.
Вместо двух вызовов функции в транзакции, мы или должны сделать 2 транзакции,
или вызывать функцию один раз, но передать ей двойку как аргумент.

# Health check

У датомика есть дурацкая проблема с количеством тредов, отведенных на health-check endpoint, внутри контейнера.
[ping-concurrency](https://docs.datomic.com/operation/deployment.html#max-threads)

Почему я должен разбираться в этом?

# Docker

Нет официального docker-image.
Нет конфигурации через env.

# Deploy

Мне нужно хранить мало данных.
Очень часто клиентам не нужна отказоустойчивость и мы запускаем один инстанс приложения.

Но я не понимаю, почему нельзя запустить transactor и приложение в одном процессе,
а данные сохранять в H2.

# Доступ к данным без репл

Это самая очевидная проблема. Довольно часто хочется зайти в консоль и посмотреть таблички.
Но тут нет ни консоли ни табличек.

Бывает, что БД живет дольше, чем код приложения.
Т.е. приложение устаревает, пишут новое приложение, а БД остается.

С Датомиком это почти наверняка не сработает.

# Масштабирование

Я не знаю истории, и предпосылок появления Датомика.
Но за эти 10 лет сервера стали очень мощными.
Если вы не "Яндекс", то вы очень долго сможете расти вертикально.

Многие БД позволяют потоково читать данные.
И это решение, если вам нужно сделать отчет по всем данным, что не помещается в память приложения.

Т.е. масштабирование чтения (Peer) в датомике теряет актуальность.

# Локальный кэш

В Датомике есть in-memory или дисковый (Valcache) кэш.

И важно отметить, что если вы берете SQL DB + Cache,
то все ваши запросы становятся key-value, вы теряете QL.

А у датомика кэшируются части B+ tree индекса, что оставляет полноценные запросы.

Я не делал полноценные бенчмарки, но `select count(*) ...` в Postgres в докере в виртуалке
с большим отрывом обгонял подобный запрос на полностью закэшированной в Valcache бд в Датомике.
Да, сравнение никакое, но заставляет задуматься.

С другой стороны, а часто ли нужно делать консистентый поиск по диапазонам в кэше?

# Полнотекстовый поиск

В Датомике такая поддержка полнотекста, что считай, что ее нет.

В итоге нужно подключать стороннее решение, разбираться, как настроить репликакцию и т.д.
Готовых решений нет.

Добавленние новой БД полностью убивает все преимущества Датоимка.
1. даже используя in-memory Датомика в тестах, вам нужно поднимать еще одну БД
2. ее нужно деплоить и скейлить
3. держать в голове еще одну парадигму хранения данных

# Большие строки

В Датомике не стоит хранить большие строки, а тем более их индексировать.
И документация рекомендует положить их "куда-то еще".

Если датомик использует другие базы данных для хранения сегментов,
то почему бы не сделать api для хранения BLOB?

# Типы данных

Вы не можете сделать свой тип атрибута.
Конечно, я слышал, что вроде бы можно как-то подлезть в `fressian`.

`java.time` уже много лет доступно, но команда не торопится добавлять поддежку этих новых типов.
